{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 거리측정 함수 정의1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(distance):\n",
    "    d1 = 30\n",
    "    y1 = 82\n",
    "    d2 = 50\n",
    "    y2 = 47\n",
    "#   d3 = 40\n",
    "    y3 = 62\n",
    "    \n",
    "    dis = ((d2-d1)/(y2-y1))*(distance-y1)+d1\n",
    "    d1 = \n",
    "    return round(dis,1)\n",
    "\n",
    "x(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2(distance):\n",
    "    d1 = 30\n",
    "    y1 = 82\n",
    "    d2 = 50\n",
    "    y2 = 47\n",
    "    d3 = 40\n",
    "    y3 = 62\n",
    "    \n",
    "    dis = (((d1*y1)+(d2*y2)+(d3*y3))/3/distance)\n",
    "    return round(dis,1)\n",
    "\n",
    "x2(62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 거리측정 + 눈 깜빡임 통합모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 혼합본 (거리 + 깜빡임)\n",
    "\n",
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config) \n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n",
    "\n",
    "def dis(distance):\n",
    "    d1 = 30\n",
    "    y1 = 82\n",
    "    d2 = 50\n",
    "    y2 = 47\n",
    "#   d3 = 40\n",
    "    y3 = 62\n",
    "    \n",
    "    dis = ((d2-d1)/(y2-y1))*(distance-y1)+d1\n",
    "    return round(dis,1)\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "sum = 0\n",
    "co = 0 \n",
    "c = 0\n",
    "cnt = 0\n",
    "st = 0\n",
    "stat = [1,1]\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img_ori = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.9, fy=0.9)\n",
    "    \n",
    "    img = img_ori.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "        \n",
    "        eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "        pred_l = model.predict(eye_input_l)\n",
    "        pred_r = model.predict(eye_input_r)\n",
    "\n",
    "        \n",
    "        state_l = '%.1f' if pred_l > 0.1 else '%.1f'\n",
    "        state_r = '%.1f' if pred_r > 0.1 else '%.1f'\n",
    "\n",
    "        state_l = state_l % pred_l\n",
    "        state_r = state_r % pred_r\n",
    "        \n",
    "#         print(stat[0]==1)\n",
    "#         print(type(state_l))\n",
    "#         print(state_l == '0.0')\n",
    "        \n",
    "        if (stat[0]==1) and (state_l == '0.0') and (stat[1]==1) and (state_r == '0.0') :\n",
    "            stat[0] = 0\n",
    "            stat[1] = 0\n",
    "            cnt += 1\n",
    "        \n",
    "        if (state_l == '1.0') :\n",
    "            stat[0] = 1\n",
    "            \n",
    "        if (state_r == '1.0') :\n",
    "            stat[1] = 1\n",
    "        \n",
    "#         print(state_l,state_r)\n",
    "#         print('st : ',st)\n",
    "#         print(stat,cnt)\n",
    "        \n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "        cv2.putText(img, \"state : {}\".format(cnt), (0,80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (71,100,62), 2)\n",
    "\n",
    "\n",
    "        # 눈 사이 거리 측정\n",
    "        \n",
    "        centerX_l = eye_rect_l[0] + (eye_rect_l[2] - eye_rect_l[0])/2\n",
    "        centerY_l = eye_rect_l[1] + (eye_rect_l[3] - eye_rect_l[1])/2\n",
    "        centerX_r = eye_rect_r[0] + (eye_rect_r[2] - eye_rect_r[0])/2 \n",
    "        centerY_r = eye_rect_r[1] + (eye_rect_r[3] - eye_rect_r[1])/2\n",
    "\n",
    "        distance = np.sqrt((centerX_r- centerX_l)**2 + (centerY_r- centerY_l)**2)\n",
    "        #print(distance)\n",
    "        \n",
    "        #c = x2(distance)\n",
    "        #print(c)\n",
    "        \n",
    "        sum = sum + distance\n",
    "        co = co + 1\n",
    "\n",
    "        if(co > 10):\n",
    "            avg = sum / co\n",
    "#             print(\"dis = {}\".format(avg))\n",
    "            \n",
    "            c = dis(distance)\n",
    "                    \n",
    "            sum = 0\n",
    "            co = 0 \n",
    "        # 눈 사이 거리값 텍스트 표시\n",
    "        cv2.putText(img, \"distance : \" + str(c) +\" cm\", (0,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (71,200,62), 2)\n",
    "        \n",
    "    cv2.imshow('reqsult', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cap.release()    \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 플라스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 26, 34, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 34, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config) \n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "    eye_img = img[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n",
    "\n",
    "def dis(distance):\n",
    "    d1 = 30\n",
    "    y1 = 82\n",
    "    d2 = 50\n",
    "    y2 = 47\n",
    "#   d3 = 40\n",
    "    y3 = 62\n",
    "    \n",
    "    dis = ((d2-d1)/(y2-y1))*(distance-y1)+d1\n",
    "    return round(dis,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://192.168.56.1:9000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, redirect, request, Response, jsonify\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "sum1 = 0\n",
    "co = 0 \n",
    "c = 0\n",
    "cnt = 0\n",
    "spec = {}\n",
    "stat=[1,1]\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/re\", methods=['POST']) \n",
    "def re():\n",
    "    print(request.method)\n",
    "    sum1 = 0\n",
    "    co = 0 \n",
    "    c = 0\n",
    "    cnt = 0\n",
    "    if request.method == 'POST':\n",
    "        one_data = request.form['img']\n",
    "        imgdata = base64.b64decode(one_data)\n",
    "        image = Image.open(io.BytesIO(imgdata))\n",
    "        img90 = image.rotate(90)\n",
    "        \n",
    "        #안드로이드에서 전송된 이미지 확인\n",
    "        \n",
    "        pil_image = img90.convert('RGB') \n",
    "        open_cv_image = np.array(pil_image) \n",
    "        # Convert RGB to BGR \n",
    "        open_cv_image = open_cv_image[:, :, ::-1].copy() \n",
    "\n",
    "        img_ori = cv2.resize(open_cv_image, dsize=(0, 0), fx=0.9, fy=0.9)\n",
    "        \n",
    "        img = img_ori.copy()\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         img90 = cv2.rotate(img_gray, cv2.ROTATE_90_CLOCKWISE)\n",
    "        print('컨버터 완료')\n",
    "\n",
    "        display(plt.imshow(img))\n",
    "        display(plt.show())\n",
    "        \n",
    "        faces = detector(img)\n",
    "        \n",
    "        print('얼굴찾기 전')\n",
    "        spec = {'dist':c}\n",
    "        json_val=json.dumps(spec)\n",
    "        \n",
    "        for face in faces:\n",
    "            shapes = predictor(img_gray, face)\n",
    "            shapes = face_utils.shape_to_np(shapes)\n",
    "            print('얼굴 찾음')\n",
    "\n",
    "            eye_img_l, eye_rect_l = crop_eye(img_gray, eye_points=shapes[36:42])\n",
    "            eye_img_r, eye_rect_r = crop_eye(img_gray, eye_points=shapes[42:48])\n",
    "            print('눈 찾음')\n",
    "            \n",
    "            eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "            eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "            eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "            print('사이즈 조정')\n",
    "\n",
    "            eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "            eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "            pred_l = model.predict(eye_input_l)\n",
    "            pred_r = model.predict(eye_input_r)\n",
    "            \n",
    "            # 눈 사이 거리 측정\n",
    "\n",
    "            centerX_l = eye_rect_l[0] + (eye_rect_l[2] - eye_rect_l[0])/2\n",
    "            centerY_l = eye_rect_l[1] + (eye_rect_l[3] - eye_rect_l[1])/2\n",
    "            centerX_r = eye_rect_r[0] + (eye_rect_r[2] - eye_rect_r[0])/2 \n",
    "            centerY_r = eye_rect_r[1] + (eye_rect_r[3] - eye_rect_r[1])/2\n",
    "\n",
    "            distance = np.sqrt((centerX_r- centerX_l)**2 + (centerY_r- centerY_l)**2)\n",
    "            c = dis(distance)\n",
    "            \n",
    "            state_l = '%.1f' if pred_l > 0.1 else '%.1f'\n",
    "            state_r = '%.1f' if pred_r > 0.1 else '%.1f'\n",
    "\n",
    "            state_l = state_l % pred_l\n",
    "            state_r = state_r % pred_r\n",
    "\n",
    "    #         print(stat[0]==1)\n",
    "    #         print(type(state_l))\n",
    "    #         print(state_l == '0.0')\n",
    "\n",
    "    #오리지날 깜빡임 횟수체크\n",
    "#             if (stat[0]==1) and (state_l == '0.0') and (stat[1]==1) and (state_r == '0.0') :\n",
    "#                 stat[0] = 0\n",
    "#                 stat[1] = 0\n",
    "#                 cnt += 1\n",
    "\n",
    "#             if (state_l == '1.0') :\n",
    "#                 stat[0] = 1\n",
    "\n",
    "#             if (state_r == '1.0') :\n",
    "#                 stat[1] = 1\n",
    "            if (stat[0]==1 and stat[1]==1):\n",
    "                if (state_l == '0.0') and (state_r == '0.0'):\n",
    "                    stat[0] = 0\n",
    "                    stat[1] = 0\n",
    "                    cnt += 1\n",
    "\n",
    "            if (state_l == '1.0') :\n",
    "                stat[0] = 1\n",
    "\n",
    "            if (state_r == '1.0') :\n",
    "                stat[1] = 1\n",
    "        \n",
    "#             cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "#             cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "            \n",
    "            print(state_l,\"-\",state_r)\n",
    "#             print('메소드 적용 후 :',c,\"\\,\",cnt)\n",
    "#             print(type(c))\n",
    "            spec = {'dist':float(c), 'blink':cnt}\n",
    "            print('딕션 적용 후 :',spec)\n",
    "            json_val=json.dumps(spec)\n",
    "            print('제이슨 적용 후 :',json_val)\n",
    "            \n",
    "            print('for문 실행 완료')\n",
    "#             cv2.putText(img, \"distance : \" + str(json_val[0]) +\" cm\", (0,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (71,200,62), 2)\n",
    "    \n",
    "    resp = Response(\"{}\".format(json_val), mimetype='text/plain')\n",
    "    resp.headers['Access-Control-Allow-Origin'] = '*'\n",
    "    resp.headers['Access-Control-Allow-Methods'] = 'POST'\n",
    "    resp.headers['Access-Control-Allow-Headers'] = 'Origin'\n",
    "    return resp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('192.168.56.1', 9000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
